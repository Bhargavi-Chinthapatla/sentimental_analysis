{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement/Goal\n",
    " - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Tasks:\n",
    "- Scrape all the info from the website\n",
    " \n",
    "## Completed Tasks:\n",
    "- Scrape\n",
    "    - List by just straight up adding the number to 6\n",
    "    - Grab all from each list\n",
    "    - add: ?part=single per page\n",
    "- Extra info grabbing\n",
    "    - Time in year and Quarter\n",
    "    - Company Name in Ticker\n",
    "    - Speaker Name in CEO or CFO\n",
    "- Have the sections seperated between Main Speech and Q/A Sections\n",
    "    - Sentiment\n",
    "    - Complexity in Gunning Fog Score\n",
    " \n",
    "## Conquered Challenges:\n",
    "- Challenge:\n",
    "    -Recieving a captcha\n",
    "        - Changed the user agent\n",
    "        - Made the user agent change everytime the browser was launched\n",
    "        - Slowed the scraper's roll by 20 per round\n",
    "    - Timeout Error\n",
    "        - Put in a SINGLE Try/Except loop that had 5 to 20 counts of it. \n",
    "    - Solution(s):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Scraping Libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "import re\n",
    "\n",
    "# NLP Libraries\n",
    "from textblob import TextBlob\n",
    "import textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\svr\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from selenium) (1.25.9)\n",
      "Installing collected packages: selenium\n",
      "Successfully installed selenium-3.141.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.4; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\svr\\appdata\\local\\programs\\python\\python37\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sentamentize(text):\n",
    "    return TextBlob(str(text)).sentiment.polarity\n",
    "\n",
    "def open_browser(alt_user_name = 'Thank you for your website'):\n",
    "    opts = Options()\n",
    "    opts.add_argument(\"user-agent=\" + str(alt_user_name))\n",
    "    path = '../Garage/chromedriver'         # Path to Chromedriver\n",
    "    return webdriver.Chrome(executable_path = path, options=opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Options' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-ff01183dd78c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mb_url\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'https://seekingalpha.com/earnings/earnings-call-transcripts/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpage_num\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mbrowser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen_browser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Y'all are great \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[1;31m# I put in a \"unique\" user agent name to help throw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m# off the captcha.  This worked for only so long.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-9c15389e7591>\u001b[0m in \u001b[0;36mopen_browser\u001b[1;34m(alt_user_name)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mopen_browser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malt_user_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Thank you for your website'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mopts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mopts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"user-agent=\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malt_user_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'../Garage/chromedriver'\u001b[0m         \u001b[1;31m# Path to Chromedriver\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Options' is not defined"
     ]
    }
   ],
   "source": [
    "# Scraping urls of each transcript before the next step.\n",
    "# Included were printouts of the page number the url was found on.\n",
    "# I caught just over 6,000 urls at the time & stopped because of captchas\n",
    "b_url='https://seekingalpha.com/earnings/earnings-call-transcripts/'\n",
    "for page_num in range(1,1001):\n",
    "    browser = open_browser(\"Y'all are great \" + str(page_num))\n",
    "        # I put in a \"unique\" user agent name to help throw\n",
    "        # off the captcha.  This worked for only so long.\n",
    "    current_ts_list = b_url + str(page_num)\n",
    "    browser.get(current_ts_list)\n",
    "    elements_list = browser.find_elements_by_class_name('dashboard-article-link')\n",
    "    urls    = [el.get_attribute('href') + '?part=single' for el in elements_list]\n",
    "    headers = [el.text for el in elements_list]\n",
    "    print('scraping', page_num)\n",
    "    #sleep(20)\n",
    "    for transcript_num in range(len(urls)):\n",
    "        current_transcript = {\n",
    "            'header'   : headers[transcript_num],\n",
    "            'url'      : urls[transcript_num],\n",
    "            'page_list': page_num\n",
    "        }\n",
    "        url_list.append(current_transcript)\n",
    "    browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "ERROR 0\n",
      "--------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'browser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-a47398a821e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mrow_num\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'transcript'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0murl_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'transcript'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow_num\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'url_df' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-a47398a821e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'--------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[1;31m#### Suggestions for the future scraper.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;31m# if browser:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'browser' is not defined"
     ]
    }
   ],
   "source": [
    "# Scraping every individual url in the df to return the full \n",
    "# transcript to be split and analyzed later.\n",
    "for i in range(20):  # This allows for timeout errors w/oo crashing\n",
    "    try:\n",
    "        for row_num in range(len(url_df['transcript'])):\n",
    "            if url_df['transcript'][row_num] == 0:\n",
    "                \n",
    "                # Go to url and obtain the full transcript\n",
    "                browser = open_browser()\n",
    "                browser.get(url_df['url'][row_num])\n",
    "                print('scraping',row_num,\n",
    "                    datetime.fromtimestamp(time()\n",
    "                    ).strftime('%H:%M:%S'),\n",
    "                    url_df['header'][row_num][:85]) # End of print\n",
    "                \n",
    "                soup    = BeautifulSoup(browser.page_source)\n",
    "                article = soup.find('article')\n",
    "                url_df['transcript'][row_num] = [item.text for \n",
    "                    item in article.find_all('p')]\n",
    "                browser.close()\n",
    "                sleep(20)\n",
    "            else:\n",
    "                pass\n",
    "    except:\n",
    "        print('--------')\n",
    "        print('ERROR', i)\n",
    "        print('--------')\n",
    "        sleep(100)\n",
    "        browser.close()\n",
    "        #### Suggestions for the future scraper.\n",
    "        # if browser:\n",
    "        #    browser.close()\n",
    "        # else:\n",
    "        #    print(\"\"\"Browser was already closed.  \n",
    "        #    This wasn't a timeout error\"\"\")\n",
    "        # For info on catching the errors that we want try:\n",
    "        # https://stackoverflow.com/questions/33239308/how-to-\n",
    "        # get-exception-message-in-python-properly/33239954"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/url_df.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-51fd30346bd7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0murl_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data/url_df.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\svr\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    686\u001b[0m     )\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\svr\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\svr\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 948\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\svr\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\svr\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2010\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/url_df.csv'"
     ]
    }
   ],
   "source": [
    "url_df = pd.read_csv('./data/url_df.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing of Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The speech and QA columns in this were a mistake from a previous attempt.  They are written over later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'url_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-a117d4b13811>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0murl_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'url_df' is not defined"
     ]
    }
   ],
   "source": [
    "url_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28336"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(url_df['QA'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original transcript columns were filled with lists rather than just strings.  This allowed me to seperate the speech and QA sections allong the string value \"Question-and-Answer Session\".  Unfortunatly, upon being saved these values have been transformed into simple strings.  Luckily, the splitting has already taken place beforehand.  But wont be super able to be shown for the future.   \n",
    "\n",
    "The remainder of the code ahs been left in place to show how these things were done in the first place as best as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = url_df.head(6000) # Rounding the number to 6,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "df.drop(['page_list', 'url'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I recieved a lot of these copy warnings during this project and I'll have to look into them more later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Creating new columns on the split at the QAS\n",
    "# And then joining those chunks together.\n",
    "\n",
    "# I originally had a for-loop that had to find the specific instance\n",
    "# of the QAS but then discovered .index() and that made life easier.\n",
    "\n",
    "QAS = 'Question-and-Answer Session'\n",
    "\n",
    "# Defining a function to return the speech section.\n",
    "def speech_function(x):\n",
    "    if QAS in x:\n",
    "        result = ''.join([words for words in x[1:x.index(QAS)]if len(words) >= 100])\n",
    "    else:\n",
    "        result = np.nan\n",
    "    return result\n",
    "\n",
    "# Defining a function to return the Q and Q section.\n",
    "def QA_sec_function(x):\n",
    "    if QAS in x:\n",
    "        result = ''.join([words for words in x[x.index(QAS) +1:] if len(words) >= 25])\n",
    "    else:\n",
    "        result = np.nan\n",
    "    return result\n",
    "\n",
    "df['speech'] = df['transcript'].map(lambda x: speech_function(x))\n",
    "df['QA']     = df['transcript'].map(lambda x: QA_sec_function(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Requested Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:5434: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "na's filled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speech_sentiment Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QA_sentiment Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speech_complexity Done\n",
      "QA_complexity Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Performing the actual analysis that was requested \n",
    "# on the two different sections.\n",
    "df['speech'].fillna('', inplace = True)\n",
    "df['QA'].fillna('', inplace = True)\n",
    "print(\"na's filled\")\n",
    "\n",
    "# Creating a sentiment columns from the speech & QA columns\n",
    "df['speech_sentiment']  = df['speech'].map(lambda x: \n",
    "                                    Sentamentize(x))\n",
    "print('speech_sentiment Done')\n",
    "df['QA_sentiment']      = df['QA'].map(lambda x: \n",
    "                                    Sentamentize(x))\n",
    "print('QA_sentiment Done')\n",
    "\n",
    "# Creating a complexity column from the speech & QA columns\n",
    "df['speech_complexity'] = df['speech'].map(lambda x: \n",
    "                                    textstat.gunning_fog(x))\n",
    "print('speech_complexity Done')\n",
    "df['QA_complexity']     = df['QA'].map(lambda x: \n",
    "                                    textstat.gunning_fog(x))\n",
    "print('QA_complexity Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./../EC_Analyzed.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/EC_Analyzed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>header</th>\n",
       "      <th>speech</th>\n",
       "      <th>QA</th>\n",
       "      <th>transcript</th>\n",
       "      <th>speech_sentiment</th>\n",
       "      <th>QA_sentiment</th>\n",
       "      <th>speech_complexity</th>\n",
       "      <th>QA_complexity</th>\n",
       "      <th>time</th>\n",
       "      <th>company</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vocera Communications (VCRA) CEO Brent Lang on...</td>\n",
       "      <td>Good afternoon, ladies and gentlemen and welco...</td>\n",
       "      <td>[Operator Instructions] Your first question is...</td>\n",
       "      <td>['Vocera Communications (NYSE:VCRA) Q4 2018 Ea...</td>\n",
       "      <td>0.169205</td>\n",
       "      <td>0.110270</td>\n",
       "      <td>15.64</td>\n",
       "      <td>12.72</td>\n",
       "      <td>Q4 2018</td>\n",
       "      <td>Vocera Communications (VCRA)</td>\n",
       "      <td>CEO Brent Lang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Klepierre SA (KLPEF) CEO Jean-Michel Rene Gaul...</td>\n",
       "      <td>Good morning, everyone. Jean-Michel and myself...</td>\n",
       "      <td>Michel Varaldo, Société Générale. Two question...</td>\n",
       "      <td>['Klepierre SA (OTCPK:KLPEF) Q4 2018 Earnings ...</td>\n",
       "      <td>0.172358</td>\n",
       "      <td>0.139347</td>\n",
       "      <td>13.58</td>\n",
       "      <td>11.69</td>\n",
       "      <td>Q4 2018</td>\n",
       "      <td>Klepierre SA (KLPEF)</td>\n",
       "      <td>CEO Jean-Michel Rene Gault</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ESCO Technologies Inc. (ESE) CEO Vic Richey on...</td>\n",
       "      <td>Good day and welcome to the ESCO Technologies ...</td>\n",
       "      <td>Thank you. [Operator Instructions] And our fir...</td>\n",
       "      <td>['ESCO Technologies Inc. (NYSE:ESE) Q1 2019 Ea...</td>\n",
       "      <td>0.144630</td>\n",
       "      <td>0.188894</td>\n",
       "      <td>19.51</td>\n",
       "      <td>14.81</td>\n",
       "      <td>Q1 2019</td>\n",
       "      <td>ESCO Technologies Inc. (ESE)</td>\n",
       "      <td>CEO Vic Richey</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              header  \\\n",
       "0  Vocera Communications (VCRA) CEO Brent Lang on...   \n",
       "1  Klepierre SA (KLPEF) CEO Jean-Michel Rene Gaul...   \n",
       "2  ESCO Technologies Inc. (ESE) CEO Vic Richey on...   \n",
       "\n",
       "                                              speech  \\\n",
       "0  Good afternoon, ladies and gentlemen and welco...   \n",
       "1  Good morning, everyone. Jean-Michel and myself...   \n",
       "2  Good day and welcome to the ESCO Technologies ...   \n",
       "\n",
       "                                                  QA  \\\n",
       "0  [Operator Instructions] Your first question is...   \n",
       "1  Michel Varaldo, Société Générale. Two question...   \n",
       "2  Thank you. [Operator Instructions] And our fir...   \n",
       "\n",
       "                                          transcript  speech_sentiment  \\\n",
       "0  ['Vocera Communications (NYSE:VCRA) Q4 2018 Ea...          0.169205   \n",
       "1  ['Klepierre SA (OTCPK:KLPEF) Q4 2018 Earnings ...          0.172358   \n",
       "2  ['ESCO Technologies Inc. (NYSE:ESE) Q1 2019 Ea...          0.144630   \n",
       "\n",
       "   QA_sentiment  speech_complexity  QA_complexity     time  \\\n",
       "0      0.110270              15.64          12.72  Q4 2018   \n",
       "1      0.139347              13.58          11.69  Q4 2018   \n",
       "2      0.188894              19.51          14.81  Q1 2019   \n",
       "\n",
       "                        company                     speaker  \n",
       "0  Vocera Communications (VCRA)              CEO Brent Lang  \n",
       "1          Klepierre SA (KLPEF)  CEO Jean-Michel Rene Gault  \n",
       "2  ESCO Technologies Inc. (ESE)              CEO Vic Richey  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correcting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk(regex, x, speaker = False):\n",
    "    string = re.search(regex, x)\n",
    "    if string == None:\n",
    "        string = np.nan\n",
    "    else:\n",
    "        string = string.group()\n",
    "        \n",
    "    if type(string) == str and speaker == True:\n",
    "        string = string.strip(' on').strip('] ').strip(') ')\n",
    "    return string\n",
    "\n",
    "# Returns the time in quarter/year\n",
    "df['time']    = df['header'].map(lambda x: chunk(r'Q\\d \\d+',x))\n",
    "# Returns the Company Name\n",
    "df['company'] = df['header'].map(lambda x: \n",
    "                        chunk(r'.+(\\(|\\[)[A-Z.:,-]+(\\)|\\])',x))\n",
    "# Returns Speaker & Title\n",
    "df['speaker'] = df['header'].map(lambda x: \n",
    "                        chunk(r'(\\)|\\]) .+ on', x, True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used the following code to identify which strings hadn't gotten picked up by my original regex finder(s).  I then went back and improved my  code as neccessary, however I was only able to clean and improve so much for the speaker column (especially when many weren't  listed) and the time column was awash in a virety of different  formats and  as such I decided not to bother myself with attempting to untangle  that web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HollyFrontier Presents at Acquisition of Sonneborn M&A Conference - Transcript\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "mask = df['company'].isna()\n",
    "for i in df[mask]['header']:\n",
    "    print(i)\n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>company</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speech_sentiment</th>\n",
       "      <th>speech_complexity</th>\n",
       "      <th>QA_sentiment</th>\n",
       "      <th>QA_complexity</th>\n",
       "      <th>header</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q4 2018</td>\n",
       "      <td>Vocera Communications (VCRA)</td>\n",
       "      <td>CEO Brent Lang</td>\n",
       "      <td>0.169205</td>\n",
       "      <td>15.64</td>\n",
       "      <td>0.110270</td>\n",
       "      <td>12.72</td>\n",
       "      <td>Vocera Communications (VCRA) CEO Brent Lang on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q4 2018</td>\n",
       "      <td>Klepierre SA (KLPEF)</td>\n",
       "      <td>CEO Jean-Michel Rene Gault</td>\n",
       "      <td>0.172358</td>\n",
       "      <td>13.58</td>\n",
       "      <td>0.139347</td>\n",
       "      <td>11.69</td>\n",
       "      <td>Klepierre SA (KLPEF) CEO Jean-Michel Rene Gaul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q1 2019</td>\n",
       "      <td>ESCO Technologies Inc. (ESE)</td>\n",
       "      <td>CEO Vic Richey</td>\n",
       "      <td>0.144630</td>\n",
       "      <td>19.51</td>\n",
       "      <td>0.188894</td>\n",
       "      <td>14.81</td>\n",
       "      <td>ESCO Technologies Inc. (ESE) CEO Vic Richey on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q1 2019</td>\n",
       "      <td>Electrovaya Inc. (EFLVF)</td>\n",
       "      <td>Management</td>\n",
       "      <td>0.183982</td>\n",
       "      <td>18.14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.38</td>\n",
       "      <td>Electrovaya Inc. (EFLVF) Management on Q1 2019...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q4 2018</td>\n",
       "      <td>Great-West Lifeco's (GWLIF)</td>\n",
       "      <td>CEO Paul Mah</td>\n",
       "      <td>0.066531</td>\n",
       "      <td>18.80</td>\n",
       "      <td>0.105221</td>\n",
       "      <td>10.08</td>\n",
       "      <td>Great-West Lifeco's (GWLIF) CEO Paul Mahon on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      time                       company                     speaker  \\\n",
       "0  Q4 2018  Vocera Communications (VCRA)              CEO Brent Lang   \n",
       "1  Q4 2018          Klepierre SA (KLPEF)  CEO Jean-Michel Rene Gault   \n",
       "2  Q1 2019  ESCO Technologies Inc. (ESE)              CEO Vic Richey   \n",
       "3  Q1 2019      Electrovaya Inc. (EFLVF)                  Management   \n",
       "4  Q4 2018   Great-West Lifeco's (GWLIF)                CEO Paul Mah   \n",
       "\n",
       "   speech_sentiment  speech_complexity  QA_sentiment  QA_complexity  \\\n",
       "0          0.169205              15.64      0.110270          12.72   \n",
       "1          0.172358              13.58      0.139347          11.69   \n",
       "2          0.144630              19.51      0.188894          14.81   \n",
       "3          0.183982              18.14      0.000000          13.38   \n",
       "4          0.066531              18.80      0.105221          10.08   \n",
       "\n",
       "                                              header  \n",
       "0  Vocera Communications (VCRA) CEO Brent Lang on...  \n",
       "1  Klepierre SA (KLPEF) CEO Jean-Michel Rene Gaul...  \n",
       "2  ESCO Technologies Inc. (ESE) CEO Vic Richey on...  \n",
       "3  Electrovaya Inc. (EFLVF) Management on Q1 2019...  \n",
       "4  Great-West Lifeco's (GWLIF) CEO Paul Mahon on ...  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.DataFrame(df, columns = [\n",
    "    'time',\n",
    "    'company',\n",
    "    'speaker',\n",
    "    'speech_sentiment',\n",
    "    'speech_complexity',\n",
    "    'QA_sentiment',\n",
    "    'QA_complexity',\n",
    "    'header'\n",
    "])\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('./data/Final_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breaking up the csv's so I can easily save them to github.\n",
    "\n",
    "Maybe.  First I'm just going to put them elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('./data/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
